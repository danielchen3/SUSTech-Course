# CS324 Deep Learning Revise

## History

1.  Deep learning relationship

   <img src="image-20241230104946166.png" alt="image-20241230104946166" style="zoom:25%;" />

2.  First wave: cybernetics(1950-1970å·¦å³)

3. Second wave: back propagation, MLP, lots of cool ideasâ€¦(1980-2000 å·¦å³): MLP, RNN, LSTM, CNN

4. NN blooming again(2010å·¦å³) Advanced CNN, AlexNet, VGG



## Math

å‡ ä¸ªå…³é”®çš„çŸ©é˜µçŸ¥è¯†

1. Norm èŒƒæ•° L2èŒƒæ•° $||v|| _{2}=\sqrt{v_1^2+v_2^2+â‹¯+v_n^2}$

2. orthogonalçŸ©é˜µï¼ŒçŸ©é˜µçš„é€†ç­‰äºå…¶è½¬ç½®

3. Sigmoid $\sigma(x) = \frac{1}{1+exp(-x)}$ï¼ŒèŒƒå›´0-1

4. npæ•°ç»„åœ¨åŠ ä¸Šä¸€ä¸ªrelativelyå¾ˆå°çš„æ•°ä¸ä¼šæœ‰å½±å“ 

   ````python
   a = np.array([0., 1e-8]).astype('float32')
   ````



## Perceptron && Back propagation

Fully connected NN

åŸºç¡€æ„ŸçŸ¥å™¨æœ‰ä»¥ä¸‹ç»„æˆéƒ¨åˆ†
$$
ğ‘“(ğ‘¥) = ğ‘ ğ‘–ğ‘”ğ‘›(ğ‘¤ â‹… ğ‘¥ + ğ‘) 
$$

$$
ğ‘ ğ‘–ğ‘”ğ‘›(ğ‘¥) = +1, ğ‘¥ â‰¥ 0;âˆ’1 , ğ‘¥ < 0
$$

Loss Function: Cross Entropy 
$$
L(y^{'}) = -\sum log(y_i^{'})* y_i
$$
å¯¹å…¶ä¸­ä¸€ä¸ª$y_i^{'}$å¯è¿›è¡Œæ±‚å¯¼

output units, Hidden units, ...

Activation: 

1. sigmoid output(binary variable): 
   $$
   \sigma (x) = \frac {1} {1+exp(-x)}
   $$

   $$
   y = \sigma(wx+b)
   $$

   $$
   gradient = \sigma(x) * (1-\sigma(x))
   $$

2. softmax output(probability distribution):
   $$
   softmax(x_i) = \frac {exp(x_i)}{\sum exp(x_j)}
   $$

3. Hidden units ReLu $a = h(x) = max(x,0)$

4. tanh
   $$
   tanh(x) = \frac {e^x - e^{-x}} {e^x + e^{-x}}
   $$

   $$
   gradient = 1 - tanh^2(x)
   $$

### Forward propagation

æµç¨‹æ˜¯ï¼Œå¯¹æ¯ä¸€å±‚è¿›è¡Œè®¡ç®—ï¼Œç„¶åæ¿€æ´», åˆ°æœ€åä¸€å±‚çš„æ—¶å€™è¿›è¡Œè¾“å‡ºå±‚æ¿€æ´»



### Back propagation

åå‘ä¼ æ’­çš„purpose: é€šè¿‡æ¢¯åº¦ä¸‹é™ä¼˜åŒ–ç½‘ç»œæƒé‡

é“¾å¼æ³•åˆ™ï¼Œ**å°±æ˜¯å‰é¢æ‰€æœ‰ä¼ æ’­å›æ¥çš„è·¯å¾„ä¸­æ¢¯åº¦ä¹˜ç§¯ä¹‹å’Œ**

çŸ©é˜µè¡¨ç¤ºï¼Œå°±æ˜¯$\frac {dy} {dx} ^T$

å–å†³äºä¸Šä¸€æ¬¡çš„æœ€åçš„gradient

<img src="image-20241230121157021.png" alt="image-20241230121157021" style="zoom:25%;" />

1. Local gradient æœ€åä¸€æ­¥çš„gradient

2. Upstream gradient ä»é«˜å±‚å›æ¥çš„gradientä¹˜ç§¯

   <img src="image-20241230122231111.png" alt="image-20241230122231111" style="zoom:25%;" />

   <img src="image-20241230133720020.png" alt="image-20241230133720020" style="zoom:25%;" />

3. å…³äºåå‘ä¼ æ’­å…·ä½“è®¡ç®—çš„ä¾‹å­å¾ˆé‡è¦ï¼ï¼ leture4 - 2 page-20

4. z = x*W

   <img src="image-20241230142322891.png" alt="image-20241230142322891" style="zoom:25%;" />

   <img src="image-20241230142501679.png" alt="image-20241230142501679" style="zoom:25%;" />



## Optimization && Regularization

1. Batch gradient descentï¼Œå°±æ˜¯æŠŠä¸€äº›æ•°æ®é›†çš„gradientæ±‚å¹³å‡ç„¶åä¸€èµ·ä¸‹é™ï¼Œmotivation(advantage)?

   1. å‡å°äº†æ³¢åŠ¨çš„éšæœºæ€§
   2. å¯ä»¥ç»“åˆäºŒé˜¶å¯¼æ›´å¥½çš„ç¡®å®šä¸‹é™æ–¹å‘

   å½“ç„¶ä¹Ÿæœ‰ä¸€äº›disadvantage:

   1. æ•°æ®é›†å¤ªå¤§äº†å¯èƒ½é€ æˆä¸€èµ·ä¸‹é™ä¸ç°å®
   2. å†…å­˜å ç”¨å¤§
   3. å¯èƒ½é™·å…¥å±€éƒ¨æœ€ä¼˜

2. Stochastic gradient descent, å•ä¸ªæ ·æœ¬æ›´æ–°å¸¦æœ‰éšæœºæ€§ï¼Œåˆ©äºè·³å‡ºå±€éƒ¨æœ€ä¼˜ï¼Œä¼˜ç‚¹ï¼š

   1. é€Ÿåº¦æ›´å¿«ï¼Œæ¯æ¬¡æ›´æ–°è®¡ç®—é‡å°
   2. randomness help avoid overfitting

   ä½†æ˜¯éœ‡è¡ä¼šæ›´æ˜æ˜¾ï¼Œè€Œä¸”ç”±äºæ˜¯æ¯æ¬¡éƒ½è¦æ›´æ–°å®Œå‚æ•°ä¹‹åå†ä¸‹ä¸€ä¸ªï¼Œæ‰€ä»¥æ— æ³•å¹¶è¡Œè®¡ç®—

3. Mini-batch gradient descent, motivationæ˜¯ç»¼åˆäº†SGDå’ŒBGDï¼Œè®¤ä¸ºç»¼åˆä»–ä»¬çš„ä¼˜ç‚¹ï¼Œæ—¢ä¸æ ·æœ¬é‡å¤ªå°‘éœ‡è¡å¤§æ— æ³•å¹¶è¡Œè®¡ç®—ï¼Œåˆåˆ©äºè·³å‡ºå±€éƒ¨æœ€ä¼˜

4. SGD vs GD

   1. SGDåœ¨æ•°æ®éšç€æ—¶é—´å˜åŒ–æ—¶å€™è¡¨ç°è‰¯å¥½
   2. SGDå¯ä»¥ä¼˜å…ˆé€‰æ‹©è¯¯å·®å¤§æ¢¯åº¦å¤§çš„æ ·æœ¬é€‰æ‹©ä¼˜å…ˆè®­ç»ƒï¼Œè¿™æ ·å¯ä»¥ä½¿å‚æ•°æ›´æ–°å¹…åº¦æ›´æ˜æ˜¾ï¼Œæ›´å¿«å‡å°‘æ€»ä½“è¯¯å·®
   3. å¯ä»¥ä¼˜åŒ–é€‰æ‹©ä¿¡æ¯é‡æ›´å¤§çš„æ ·æœ¬è¿›è¡Œè®­ç»ƒ

5. **Optimization**

   å¼•å…¥optimizationçš„motivationæ˜¯ä¼šæœ‰å±€éƒ¨å€¼, æ¢¯åº¦çˆ†ç‚¸å’Œæ¶ˆå¤±...

   1. First order information 

      - Momentum. å¼•å…¥äº†velocity parameter, æ€æƒ³å°±æ˜¯è€ƒè™‘è¿‡å»çš„æ¢¯åº¦(ç”¨vå¾—åˆ°åŠ æƒä¹‹åçš„å˜åŒ–å¹…åº¦)ï¼Œè®©ä»–ä»¬ä»¥ä¸€å®šçš„é€Ÿåº¦decayã€‚ç›®çš„æ˜¯å¯ä»¥æé«˜ç¨³å®šæ€§ï¼Œæ›´å¿«æ”¶æ•›
      - Nesterov momentum æ¯”è¾ƒä¸Šä¸€æ¡ï¼Œè¿™ä¸€ä¸ªåŸºæœ¬ç›¸ä¼¼ï¼ŒçŸ¥è¯†ä¿®æ”¹æˆäº†ç”¨future gradientï¼Œåœ¨æ¢¯åº¦è®¡ç®—ä¹‹å‰å°±æ ¹æ®ä¸Šä¸€æ­¥é¢„æµ‹ä¸€ä¸‹ä¸‹ä¸€æ¬¡çš„æ›´æ–°æ–¹å‘ï¼Œç›¸å½“äºæå‰æ›´æ–°ä¸€ä¸‹ä½ç½®ï¼Œè¿™æ ·å¯ä»¥è·å¾—better convergence

      ç„¶è€Œmomentum è¿™äº›æ–¹æ³• éœ€è¦æ‰‹åŠ¨è°ƒæ•´è¶…å‚æ•°ï¼Œæ— æ³•è‡ªåŠ¨è°ƒæ•´å­¦ä¹ ç‡ï¼Œä»è€Œå¯¼è‡´æ”¶æ•›ç¼“æ…¢ï¼Œäºæ˜¯å¼•å…¥å¯ä»¥locallyè°ƒæ•´çš„ï¼Œè€Œä¸ä»…ä»…åªèƒ½åœ¨globalä¸Šåšæ–‡ç« 

      - Ada Gradient ï¼Œåšæ³•æ˜¯è®°å½•å†å²çš„gradientæ›´æ–°å­¦ä¹ ç‡ï¼Œè¿™æ ·æ¯”è¾ƒç¨³å®šï¼Œä½†æ˜¯è¿‡é•¿çš„å†å²ä¼šè®©æ”¶æ•›å¾ˆæ…¢ã€‚ä¸»è¦æ˜¯ä¸ºå‡¸å‡½æ•°(convex function)è®¾è®¡çš„ ä½†æ˜¯å¦‚æœåˆ°äº†æ¯”è¾ƒå¤æ‚çš„æƒ…å†µä¸‹æ¯”å¦‚å±€éƒ¨æå€¼ï¼Œä»–å°±ä¼šè¿‡æ—©åœæ»ï¼Œå¯¼è‡´éš¾ä»¥è·³å‡ºå±€éƒ¨å€¼

        Adapt learning rates of model parameters by scaling them inversely proportional to the **square root of the sum of all the past squared values of the gradient**

      - RMSpropï¼Œä¸ºäº†é¿å…ä¸Šä¸€ä¸ªåšæ³•çš„å­¦ä¹ ç‡è¡°å‡è¿‡å¿«ï¼Œå¼•å…¥äº†æŒ‡æ•°åŠ æƒå¹³å‡ï¼Œæ›´åŠ å¹³æ»‘è°ƒæ•´å­¦ä¹ ç‡ è¿™ä¸ªè¿˜å¯ä»¥åœ¨éå‡¸å‡½æ•°(non-convex function)ä¸Šè¡¨ç°æ›´ä¼˜(exponential moving average)

        åŒºåˆ«å°±æ˜¯using an exponential moving average

   2. Combination: Adam (RMSprop with SGD + momentum) 

      Momentumç³»åˆ—æ–¹æ³•ä¸»è¦åœ¨ä¼˜åŒ–å‚æ•°çš„æ›´æ–°æ–¹å‘ä»¥åŠå¤§å°ä¹Ÿå°±æ˜¯æ¢¯åº¦çš„æ–¹å‘ï¼Œè€Œadaç³»åˆ—æ–¹æ³•ä¸»è¦åœ¨ä¼˜åŒ–å­¦ä¹ ç‡

      momentum -> moving average of gradient

      ada -> scale learning rate

   3. Second order information

      åˆ©ç”¨ç‰›é¡¿æ³• HessiançŸ©é˜µæä¾›æ›´åŠ ç²¾å‡†çš„æ›´æ–°æ–¹å‘

      å¯èƒ½ä¸æ€ä¹ˆè€ƒï¼Ÿ

6. Regularization

   motivation: è§£å†³è¿‡æ‹Ÿåˆoverfittingçš„é—®é¢˜

   1. L1 regularization, å¼•å…¥sparsityï¼Œå°±æ˜¯ç‰¹å¾é€‰æ‹©åˆ å»ä¸€äº›å…ƒä¹‹é—´çš„è¿æ¥
   2. L2 regularization, ç”¨é€”æœ€å¹¿(weight decay), åœ¨æŸå¤±å‡½æ•°ä¸­æ·»åŠ äº†æ‰€æœ‰æ¨¡å‹å‚æ•°ï¼ˆæƒé‡ï¼‰çš„å¹³æ–¹å’Œä½œä¸ºæƒ©ç½šé¡¹ï¼Œç›®æ ‡æ˜¯**å‡å°å‚æ•°çš„å¤§å°**ï¼Œä»è€Œé˜²æ­¢æ¨¡å‹è¿‡äºä¾èµ–æŸäº›ç‰¹å®šçš„ç‰¹å¾
   3. Dataset augmentationï¼Œè·å¾—æ›´å¤šçš„è®­ç»ƒæ•°æ®ï¼
   4. Early stoppingï¼Œåœ¨validation errorä¸Šå‡çš„æ—¶å€™å°±æ—©åœå³ä½¿training errorè¿˜åœ¨ä¸‹é™
   5. Dropout éšæœºä»¥pçš„æ¦‚ç‡deactivateä¸€äº›èŠ‚ç‚¹ è¿™æ ·å¯ä»¥æ›´å¿«çš„training, less overfitting, units more robust

7. Weight initialization

   åˆå§‹åŒ–å‚æ•°æ˜¯å¾ˆé‡è¦çš„ï¼Œè¦weight asymmetricity

   è¾ƒå¤§çš„å‚æ•°å°†ä¼šæœ‰è¾ƒå¤§çš„å½±å“ï¼Œä½†æ˜¯ä¹Ÿä¼šexploding value

   è¾ƒå°çš„å‚æ•°å½“ç„¶ä¹Ÿä¸å¥½

   æ‰€ä»¥ä¸€èˆ¬ç”¨uniform distribution

8. Data pre-processing æ•°æ®é¢„å¤„ç†

   æ¿€æ´»å‡½æ•°çš„ç”¨å¤„ï¼šé€šå¸¸æŠŠæ•°æ®é›†åˆåˆ°0é™„è¿‘ï¼Œé¿å…äº†é¥±å’Œé˜²æ­¢äº†æ¢¯åº¦æ¶ˆå¤±ç°è±¡

   one-sideé¥±å’Œä¹ŸæŒºå¥½å¯ä»¥æœ‰æ•ˆé¿å…ä¸€äº›å™ªå£°çš„æ‰°åŠ¨

9. Normalization

   ä¸»è¦åŠ¨æœºæ˜¯é€šè¿‡è°ƒæ•´æ•°æ®æˆ–æ¿€æ´»å€¼çš„åˆ†å¸ƒï¼Œä½¿å¾—ç¥ç»ç½‘ç»œçš„è®­ç»ƒè¿‡ç¨‹æ›´åŠ ç¨³å®šã€å¿«é€Ÿå¹¶ä¸”é«˜æ•ˆã€‚å…·ä½“æ¥è¯´åŠ é€Ÿæ”¶æ•›ã€é¿å…æ¢¯åº¦çˆ†ç‚¸å’Œæ¶ˆå¤± 

   Batch normalization

   1. zero-centered (å‡å»mean ç„¶ådivided by standard deviation) å¯¹inputæ•°æ®è¿›è¡Œé¢„å¤„ç†ï¼Œæ‰€ä»¥ä¹Ÿæ˜¯input-normalization
   2. å±‚å½’ä¸€åŒ–æ˜¯åœ¨æ¯ä¸ªè¾“å…¥æ ·æœ¬çš„æ‰€æœ‰ç‰¹å¾ä¸Šè¿›è¡Œæ ‡å‡†åŒ–ï¼Œè€Œä¸æ˜¯å¯¹æ•´ä¸ªå°æ‰¹æ¬¡è¿›è¡Œæ ‡å‡†åŒ– ï¼Ÿå…·ä½“è¦æŒæ¡å—â˜†
   3. **æ‰¹é‡å½’ä¸€åŒ–**ä¼šå¯¹æ¯ä¸€å±‚çš„æ¿€æ´»çš„è¾“å‡ºè¿›è¡Œæ ‡å‡†åŒ–ï¼Œä½¿å¾—å®ƒä»¬å…·æœ‰é›¶å‡å€¼å’Œå•ä½æ ‡å‡†å·®ã€‚



##  Convolutional Neural Network(CNN)

### Basics

1. motivation: å¼•å…¥CNNçš„åŠ¨æœºæ˜¯ ä¿ç•™é—´éš™ç©ºé—´ç»“æ„(å·ç§¯filter), è¾“å…¥å¾ˆå¤§æ—¶å€™ä¾æ—§ä¿è¯è®¡ç®—æ•ˆç‡(sparse connection, parameter sharing), è§£å†³å±€éƒ¨å˜å¼‚é—®é¢˜(ä¸åœ¨ä¹å±€éƒ¨çš„ç»†å°å˜åŒ–,pooling)
2. convolution
   - ä¸€ä¸ªä¾‹å­ï¼šSobel filterï¼ŒSobelæ»¤æ³¢å™¨å¸¸ç”¨äºè¾¹ç¼˜æ£€æµ‹
   - å·ç§¯è¿‡ç¨‹ï¼Œæ¯ä¸ªkernel channelä¸åŸçŸ©é˜µï¼ˆåŠ ä¸Špaddingä¹‹åï¼‰ç‚¹ä¹˜ä¹‹åæ±‚å’ŒåŠ ä¸Šbias
   - å·ç§¯ä¹‹åsizeå¯èƒ½ä¼šæœ‰ä¸ªè®¡ç®—é¢˜ï¼ï¼â˜…
   - sparse connection : å·ç§¯æ ¸è¶Šå°ï¼Œä¿¡æ¯è¶Šå°ï¼Œä¸åˆ«çš„ç¥ç»å…ƒå°±è¶Šå°‘ï¼Œæ‰€ä»¥è¿æ¥è¶Šç¨€ç–
   - parameter sharing ï¼šå…·æœ‰å¹³ç§»ä¸å˜æ€§
   - local connection: åƒconvolutionä¸€æ ·å·ç§¯ï¼Œæ‹¥æœ‰sparse connectionï¼Œä½†æ˜¯æ²¡æœ‰parameters sharing
   - strided convolution, Pooling å‡æ˜¯downsamplingçš„ç­–ç•¥ï¼Œç›®çš„æ˜¯å‡å°‘è¾“å‡ºfeature map çš„size
   - zero-padding control sizeï¼šç›¸å½“äºå¦‚æœåœ¨å¤–é¢åŠ äº†ä¸€å±‚å¡«å……å±‚ï¼Œå·ç§¯ä¹‹åsizeç›¸å¯¹äºåŸè¾“å…¥ä¸å˜(doesn't shrink! ä¹Ÿæ˜¯paddingçš„motivationï¼)
   - pooling: æ± åŒ–æ“ä½œï¼Œä¿æŒæœ€é‡è¦çš„informationå‡å°å°ºå¯¸ å½“ç„¶ä¹Ÿå¯ä»¥é€šè¿‡å¢åŠ strideæ¥å‡å°å°ºå¯¸è€Œä¸ç”¨pooling



### Structure variance

1.  LeNet-5 7-level convolutional network, couldn't scale up to larger images

2. æ¥ä¸‹æ¥å°±æ˜¯ImageNetçš„å‘å±•

   - AlexNet(5 convolutional layers + 3 fully connected layer) ç›¸å¯¹äºLeNetçš„tanhï¼Œè¿™é‡Œä½¿ç”¨ReLu,å¹¶ä¸”åŠ å…¥äº†**dropout**

   - VGG 16(key is increase the depth) è¶Šæ·±ï¼Œfilteræ•°é‡å¢åŠ ï¼Œä½¿ç”¨æ›´å°çš„æ ¸(3*3) åŸå› æ˜¯ï¼š1. å †å ç»“æ„å¤šæ¬¡Reluæ¿€æ´»å¢å¼ºè¡¨è¾¾èƒ½åŠ› 2. å‡å°‘å‚æ•°æ•°é‡

   - GoogLeNet(**inception units**, batch normalization,  image distortions, RMSprop) 

     åœ¨Inception ä¸­ å¾ˆé‡è¦çš„å±‚æ˜¯**concat layer** åˆ†æˆä¸åŒå¤§å°çš„å·ç§¯æ ¸ï¼Œç„¶ååˆå¹¶

     motivationæ˜¯å¤ªæ·±çš„ç½‘ç»œç”±äºå¤§é‡çš„parametersè€Œoverfitting AND å¤§å‹çš„å·ç§¯æ“ä½œè®¡ç®—é‡å¤ªå¤§

     æ‰€ä»¥æå‡ºäº†**å®½åº¦ä¸ºä¸»**çš„ç½‘ç»œï¼Œå³**åœ¨åŒä¸€å±‚çº§ä¸Šå¹¶è¡Œä½¿ç”¨ä¸åŒå¤§å°çš„å·ç§¯æ ¸**æ¥æå–å¤šç§å°ºåº¦çš„ç‰¹å¾ã€‚ ç„¶åä½¿ç”¨**channel Concatenate**

   - ResNet( **The residual module**ï¼Œè§£å†³**æ·±åº¦ç½‘ç»œè®­ç»ƒå›°éš¾** å’Œ **æ¢¯åº¦æ¶ˆå¤±/çˆ†ç‚¸**) é€šè¿‡æ®‹å·®å—å°è¯•è·³è¿‡ä¸€äº›è¿æ¥é¿å…è¿‡å¿«çš„è¡°å‡(æˆ–è€…æä¾›ä¸€äº›shortcutè¿›è¡Œè¿‡æ¸¡),å¼•å…¥æ®‹å·®å—å’Œæ®‹å·®é“¾æ¥ï¼Œé€šè¿‡bottleneckè¿›è¡Œè¿‡æ¸¡å¯ä»¥å‡å°‘è®¡ç®—é‡

   - FractalNet (key to good performance is not having skip connections  (residuals), but having both shallow and deep paths)

   -  Stochastic depth

   - Wide ResNet (Reduce number of residual blocks, but increase  number of feature maps in each block)

   - ResNeXt(increasing cardinality is a better way to increase capacity than increasing depth or width) è¿›è¡Œåˆ†ç»„grouped convolutions æœ€åç»“æœæ±‡èš, cardinalityå°±æ˜¯#total_group

   - DenseNet ä¸»è¦åˆ›æ–°æ˜¯**å¯†é›†è¿æ¥**ï¼Œå³æ¯ä¸ªå·ç§¯å±‚çš„è¾“å…¥ä¸ä»…ä»…æ˜¯ä¸Šä¸€å±‚çš„è¾“å‡ºï¼Œè¿˜åŒ…æ‹¬äº†æ‰€æœ‰å‰é¢å±‚çš„è¾“å‡ºã€‚è¿™ç§æ–¹å¼åœ¨æ¯ä¸€å±‚åˆ›å»ºäº†ä¸€ä¸ªâ€œå¯†é›†â€çš„è¿æ¥æ¨¡å¼ï¼Œä½¿å¾—ç½‘ç»œèƒ½å¤Ÿæ›´å¥½åœ°åˆ©ç”¨ç‰¹å¾ä¿¡æ¯ã€‚ **Dense Block**

   - æ€»ä½“æ¥è¯´ï¼Œè®¾è®¡å®—æ—¨å¦‚ä¸‹

     1. making more efficient
     2. æé«˜è¡¨è¾¾èƒ½åŠ›
     3. é€‚å½“æ—¶å€™è·³è¿‡ä¸€äº›è¿æ¥å±‚ä»¥åŠåˆ›å»ºä¸æ›´æ—©å±‚çš„è¿æ¥
     4. increase depth and reduce cost (æ¯”å¦‚ç”¨residual moduleï¼Œç”¨dense block,ç”¨concatå¹¶è¡Œè®¡ç®—å‡å°‘cost)



### Calculation

å·ç§¯æ ¸çš„æ·±åº¦(filteré€šé“æ•°)å¿…é¡»å’Œä¸Šä¸€å±‚è¾“å‡ºçš„é€šé“æ•°ä¸€è‡´ AND æŸä¸€å±‚è¾“å‡ºç‰¹å¾å›¾çš„é€šé“æ•° = å½“å‰å±‚filterçš„ä¸ªæ•°

æ‰€ä»¥å°±æ¯”å¦‚å¯¹äº32x32x3çš„å›¾åƒï¼Œä½¿ç”¨ä¸€ä¸ª5x5x3çš„å·ç§¯æ ¸ï¼Œæœ€ç»ˆä¼šå¾—åˆ°ä¸€ä¸ª28x28x1çš„ç‰¹å¾å›¾ã€‚

å…¬å¼
$$
size = \frac {a-b+2d}{c} + 1
$$




## Recurrent Neural Networks(RNN)

 long temporal dependencies æ•æ‰é•¿æœŸç‰¹å¾ä»¥åŠæ—¶åºé—®é¢˜ ä¸º motivation å¼•å…¥äº†RNN

1. Basics: å¼•å…¥Long-term memory, one-hot vector representation

2. RNN: 

   Vanilla RNN cell $h(t) = tanhW(x_t,h_{t-1})$

   BPTT (back propagation through time)

   <img src="image-20250101140309184.png" alt="image-20250101140309184" style="zoom:25%;" />

   HOWEVER, Gradients will vanish if largest singular value of $W_h^T$ is less than 1 æ‰€ä»¥ä¼šé€ æˆæ¢¯åº¦çˆ†ç‚¸ä»¥åŠæ¢¯åº¦æ¶ˆå¤±

   Exploding gradients are easily solved by rescaling or clipping the gradient BUT æ¢¯åº¦æ¶ˆå¤±éš¾ä»¥è§£å†³

3.  SO å¼•å…¥LSTM

   1. First stage, we determine the percentage of long-term to be remembered(**Forget gate**)

      <img src="image-20241130122442964.png" alt="image-20241130122442964" style="zoom: 25%;" />

   2. Second stage, we determine potential long-term memory and and percentage to remember(Update long-term memory which the input is from input gate)

      <img src="image-20241130122915213.png" alt="image-20241130122915213" style="zoom: 25%;" />

   3. Final stage, we determine potential short-term memory and and percentage to remember(Update short-term memory which is output gate)

      <img src="image-20241130123115021.png" alt="image-20241130123115021" style="zoom: 25%;" />

   4. The main difference and upgrade of LSTM compared to RNN is we can effectively solve the problem of gradient explosion and gradient vanishing. LSTM use the following components:

      1.  **Input gate**, which is to combine the input **previous hidden value and current value** and then determine how much information to update the **Long-term memory**.
      2.  **Output gate**, which is used to output current decision and determines how much information should be used to update the **Short-term memory**.
      3.  **Forget gate**, which is used to determine how much of the **Long-term memory** to remember with the combination of **previous Short-term and Long-term memory** and **current input**.

      Generally, LSTM is commonly be implemented as following:

      1. Firstly, we should determine the percentage the previous **Long-term** memory to remember. To be clear, we should use $h^{t-1}$ and $x^{t}$ to determine that. (**Forget gate**)
         $$
          f(t) = Ïƒ(W_{fx}x^{t} +W_{fh}h^{t-1} +b_f)
         $$
         where $h^{t-1}$ represent previous **Short-term memory**.

      2. Secondly, we should determine how to update **Long-term** memory using $h^{t-1}$ and $x^{t}$.

         - we compute the percentage of **Short-term memory** we should remember. That is (**Input gate**)
           $$
           i(t) = Ïƒ(W_{ix}x^{t} + W_{ih}h^{t-1} + b_{i})
           $$

         - Then, we compute potential additional **Long-term memory** with "the inspiration" of current value and add it to the previous **Long-term memory**
           $$
           g(t) = tanh(W_{gx}x^{t} + W_{gh}h^{t-1} + b_g)
           $$

           $$
           c(t) = g(t) âŠ™ i(t) + c(tâˆ’1) âŠ™ f(t)
           $$

           where $c(t)$ refers to **Long-term memory** and notice that, we use $tanh$ activation function here, because the output is within the range of $[-1,1]$

      3. Finally, we should determine our **Short-term memory** using the **New Long-term memory**

         - Similar to previous step, we compute the percentage memory we should remember from **Long-term memory** (**Output gate**)
           $$
           o(t) = Ïƒ(W_{ox}x^{t} + W_{oh}h^{t-1} + b_o)
           $$

         - Then, we compute the potential new **Short-term memory**, which is also the current output after activation
           $$
           h(t) = tanh(c(t)) âŠ™ o(t)
           $$

      Following the 3 steps below, we can build a framework of traditional LSTM.

      <img src="image-20250101141541327.png" alt="image-20250101141541327" style="zoom:25%;" />

4. Gated Recurrent Unit (GRU)

   å…³ç³»å°±æ˜¯**Get rid of separate cell state** AND Merge â€œforgetâ€ and â€œoutputâ€ gates into â€œupdateâ€ gate AND å¼•å…¥äº†reset gate

   LSTMä¸­hidden stateå’Œcell stateæ˜¯åˆ†å¼€çš„ï¼Œä½†æ˜¯GRUä¸­éƒ½æ˜¯åœ¨hidden stateä¸­ç›´æ¥å­˜å‚¨ä¿¡æ¯

5. Other RNN structures

   1. Multi-layer RNNs
   2. Bi-direction RNNs
   3. åº”ç”¨åœºæ™¯ (single/multiple input) -> (single/multiple output)  4 combinations

## Manifold Learning

motivation ä¸»è¦æ˜¯ **é™ä½ç»´åº¦**ã€**æé«˜æ•°æ®è¡¨ç¤ºæ•ˆç‡** å’Œ **ä¼˜åŒ–å­¦ä¹ è¿‡ç¨‹** because Real-world data lives in a low-dimensional non-linear manifold

**Manifold structure**ï¼ˆæµå½¢ç»“æ„ï¼‰æ˜¯ä¸€ä¸ªæ•°å­¦æ¦‚å¿µï¼ŒæŒ‡çš„æ˜¯åœ¨é«˜ç»´ç©ºé—´ä¸­ï¼Œæ•°æ®ç‚¹æˆ–è€…ç‰©ä½“å®é™…ä¸Šæ˜¯â€œåµŒå¥—â€åœ¨æŸä¸ªè¾ƒä½ç»´åº¦çš„ç©ºé—´ä¸­çš„ï¼Œæˆ–è€…è¯´ï¼Œå®ƒä»¬éµå¾ªæŸç§ä½ç»´çš„ç»“æ„ã€‚è™½ç„¶æˆ‘ä»¬è§‚å¯Ÿåˆ°çš„æ•°æ®æ˜¯é«˜ç»´çš„ï¼Œä½†å®ƒä»¬çš„æœ¬è´¨ç‰¹å¾å¯ä»¥é€šè¿‡ä¸€ä¸ªä½ç»´çš„**æµå½¢**æ¥è¡¨ç¤ºã€‚

### PCA (Principle Component Analysis)

PCA(ä¸»æˆåˆ†åˆ†æ)ï¼Œç”¨äºé™ç»´æ“ä½œï¼Œåœ¨é«˜ç»´åˆ†ææ—¶å€™å°†ç»´åº¦é™ä½

1. æ‰¾ä¸¤ä¸ªç»´åº¦ï¼Œnormalize dataå°†æ•°æ®åˆ†å¸ƒåœ¨åŸç‚¹é™„è¿‘ï¼Œç„¶åéšæœºä¸€æ¡ç›´çº¿æ‰¾åˆ°æœ€å¥½fitçš„ç›´çº¿ï¼Œæœ€å°åŒ–è·ç¦»(æœ€å¤§åŒ–é—´éš”) è¿™æ ·åšçš„ç›®çš„æ˜¯è®©ç‚¹é›†å°½é‡åˆ†æ•£
2. æ›´é«˜ç»´åº¦çš„å°±æ˜¯ä¸æ–­æŒ‰ç…§ä»¥ä¸Šçš„æ–¹æ³•å¯»æ‰¾$PC_i$ï¼Œç„¶åé€šè¿‡eigen-valueæ‰¾åˆ°å…¶å¯¹varianceçš„å æ¯”ï¼Œå¦‚æœè¯´å‰ä¸¤ä¸ªPCAæ€»å’Œå æ¯”æ¯”è¾ƒé«˜çš„è¯ï¼Œç”¨è¿™ä¸¤ä¸ªçš„åæ ‡ç³»å°±å·²ç»å¯ä»¥æ¯”è¾ƒé«˜çš„è¿‘ä¼¼åŸæ¥çš„æ•°æ®é›†äº†ã€‚



### Autoencoder(AE)

**ä½†æ˜¯PCAè€ƒè™‘æ•°æ®ç‰¹å¾æ˜¯æ­£äº¤çš„ä¹Ÿå°±æ˜¯ç‹¬ç«‹çš„ï¼Œæ‰€ä»¥åªèƒ½æ•æ‰åˆ°çº¿æ€§ç»“æ„ï¼Œæ‰€ä»¥æ•æ‰æ•°æ®ç©ºé—´ç»“æ„èƒ½åŠ›ä¾ç„¶å—é™ï¼Œæ‰€ä»¥å°±å¼•å…¥AE**

Autoencoders learn to encode and decode input via a latent space

autoencoderé’ˆå¯¹é«˜ç»´çš„æ•°æ®é™ç»´ï¼Œç›¸å¯¹äºPCAæ¥è¯´æ›´èƒ½å¤„ç†æ›´åŠ é«˜ç»´çš„æ•°æ®ï¼Œencoderé™ç»´ï¼Œdecoderè¿˜åŸç»´åº¦

1. undercomplete: code has lower dimension than input AND *f* or *g* has low capacity (e.g., linear *g*)
2. overcomplete: code has higher dimension than input AND must be regularized ä»–çš„ç›®çš„æ˜¯ Encourage the model to have other useful properties besides the ability to copy its input to its output 
3. Regularized AE
   - Sparse AE adding a cost term that penalizes the code for being larger ç›®çš„æ˜¯ extract robust features or lower the dimensionality of the input data
   - Denoising AE Instead of adding penalty, change reconstruction error to account for the introduction of noise (é‡æ„è¯¯å·®ï¼Œè€ƒè™‘æ•°æ®æœ¬èº«çš„å™ªå£°) ç›¸å½“äºåŠ å…¥ä¸€ä¸ªå™ªå£°ç„¶åå†encode è¿™æ ·è®©AEå­¦ä¹ åˆ°äº†ä¸€ä¸ªdenoising map å¯ä»¥è¿›è¡Œé™å™ª
   - Training AE combines two forces: Reconstruction and Limited capacity.
   - **Note**: the autoencoder can only afford to model the variations needed to reconstruct the training data AEå¹¶ä¸æ˜¯èƒ½è¡¨ç¤ºæ‰€æœ‰çš„få‡½æ•°
   - Contractive AE æ·»åŠ æ­£åˆ™(regularization)é¡¹åˆ°encoder (Penalizes the Frobenius norm of the Jacobian of the encoder)
   - Contractive AE and Denoising AE are able to learn the manifold structure of the data.





## VAEï¼ˆvariational autoencoderï¼‰

**ç„¶è€ŒAEç¼ºä¹ç”Ÿæˆèƒ½åŠ›, AEè¿™ä¸ªè¿‡ç¨‹å¹¶æ²¡æœ‰æ˜ç¡®çš„æ¦‚ç‡å»ºæ¨¡ï¼Œä¹Ÿæ²¡æœ‰æ˜ç¡®çš„ç”Ÿæˆè¿‡ç¨‹ã€‚ä¼ ç»ŸAEåªå…³å¿ƒå‹ç¼©æ•°æ®å’Œé‡å»ºæ•°æ®ä¹‹é—´çš„è¯¯å·®ï¼Œç¼ºä¹å¯¹ç”Ÿæˆæ•°æ®çš„æ§åˆ¶èƒ½åŠ›**

**æ‰€ä»¥å¼•å…¥VAEï¼Œé‚£ä¹ˆVAEçš„æœ€å¤§ä¼˜åŠ¿ä¹‹ä¸€æ˜¯å…¶èƒ½å¤Ÿå¯¹æ•°æ®ç”Ÿæˆè¿‡ç¨‹è¿›è¡Œå»ºæ¨¡ï¼Œå¹¶å°†è¯¥è¿‡ç¨‹é€šè¿‡æ¦‚ç‡è®ºæ¡†æ¶å®ç°ã€‚**VAEçš„æ ¸å¿ƒæ˜¯å°†æ•°æ®ç‚¹è§†ä¸ºç”±æ½œåœ¨å˜é‡ï¼ˆlatent variablesï¼‰ç”±**Latent Variableså±‚**ç”Ÿæˆçš„ï¼Œè€Œè¿™äº›æ½œåœ¨å˜é‡æœä»ä¸€ä¸ªç‰¹å®šçš„æ¦‚ç‡åˆ†å¸ƒã€‚é€šè¿‡æœ€å¤§åŒ–æ•°æ®çš„ä¼¼ç„¶å‡½æ•°ï¼ˆlikelihoodï¼‰ï¼ŒVAEèƒ½å¤Ÿ å­¦ä¹ æ•°æ®çš„ç”Ÿæˆåˆ†å¸ƒ

æœ¬èº«çš„æƒ³æ³•(motivation)æ˜¯ é’ˆå¯¹simple autoencoder, è¿™é‡Œçš„bottleneckä¹Ÿå°±æ˜¯é™ç»´ä¹‹åçš„æˆ‘ä»¬ç”¨ä¸¤ä¸ªå‚æ•°è¡¨ç¤ºï¼Œä¸€ä¸ªæ˜¯meanä¸€ä¸ªæ˜¯varï¼Œç›¸å½“äºæ˜¯è®°å½•çš„æ˜¯åˆ†å¸ƒdistributionä¸­çš„åˆ†å¸ƒä¿¡æ¯ã€‚so for one data point we can sample many codes z

**Latent Variable Layer** ç”Ÿæˆmeanå’Œvarä¸¤ä¸ªå‚æ•°ï¼Œç„¶åé€šè¿‡**sampled layer**(Reparameterization Layer)é‡å»ºç”Ÿæˆlatent variablesä¹Ÿå°±æ˜¯sampled vector zï¼Œæœ€åé€šè¿‡decoderæ¥é‡å»º

æ¥ç€ï¼Œé€šè¿‡$z=Î¼+Ïƒâ‹…Ïµ$å¾—åˆ°sampled vector $z$ , æœ€åå†ç»è¿‡decoderæ¥è¿›è¡Œé‡å»ºã€‚

loss_functionå…¶å®æ˜¯é€šè¿‡autoencoderä¸­çš„lossï¼ˆåªæ˜¯å˜æˆäº†æœŸæœ›å› ä¸ºæœ¬è´¨æ˜¯ä¸€ä¸ªåˆ†å¸ƒ, MLEæœ€å¤§ä¼¼ç„¶ä¼°è®¡ï¼‰å†åŠ ä¸ŠKLæ•£åº¦ (regularization term)	

è€Œ**KLæ•£åº¦**çš„ä½œç”¨æ˜¯**æ­£åˆ™åŒ–æ½œåœ¨ç©ºé—´**ï¼Œå®ƒè¿«ä½¿æ½œåœ¨å˜é‡çš„åˆ†å¸ƒæ¥è¿‘äºæ ‡å‡†æ­£æ€åˆ†å¸ƒã€‚è¿™æœ‰åŠ©äºé¿å…ç¼–ç å™¨è¾“å‡ºçš„æ½œåœ¨å˜é‡åˆ†å¸ƒè¿‡äºå¤æ‚ï¼Œä¸”é¿å…æ¨¡å‹å¯¹è¾“å…¥æ•°æ®çš„è¿‡æ‹Ÿåˆã€‚

**æ½œåœ¨ç©ºé—´** latent spaceçš„è®¡ç®—å¾ˆé‡è¦ï¼Œæ‰€ä»¥KLå¯¹Lossçš„å½±å“æ˜¯ä¸å¯å¿½è§†çš„

<img src="image-20250101151042370.png" alt="image-20250101151042370" style="zoom:25%;" />



## Generative adversarial networks(GAN)

ç”±VAEè¿‡æ¸¡åˆ°generative tasks, æ‰€ä»¥å°±å¼•å…¥äº†GAN

motivationæ˜¯æ³¨æ„åˆ°VAEå¯ä»¥å­¦ä¹ ç”Ÿæˆå›¾åƒ, ä½†æ˜¯æˆ‘ä»¬æ€ä¹ˆåˆ¤å®šå›¾åƒçš„è´¨é‡å‘¢ï¼Ÿloss functionæ˜¯ä»€ä¹ˆå‘¢

ä»–ä»¬åšçš„äº‹æƒ…å°±æ˜¯ï¼š

- **Generator**: G(*z*) takes random noise *z* as input and outputs a (fake) image
- **Discriminator**: D(*x*) receives an image x in input, real or fake, and estimates its probability to be real
- **Note**: both the generator and the discriminator need to be differentiable

Parameters updating process is the following formula (minimax and zero-sum game)
$$
\min_G \max_D V(D, G) = \mathbb{E}_{xï½{p_{data}(x)}}[\log D(X)] + \mathbb{E}_{zï½p_{z}(z)}[\log(1 - D(G(Z)))]
$$
<img src="image-20250102125833838.png" alt="image-20250102125833838" style="zoom:25%;" />

G is trained to minimize log(1 âˆ’ D(G(*z*))), i.e., fool the discriminator

<img src="image-20250101154326939.png" alt="image-20250101154326939" style="zoom:25%;" />

ä¸Šé¢çš„å¼å­ä¹Ÿæ˜¯Dçš„loss function, ä¸‹é¢çš„æ˜¯Gçš„loss function

- DCGAN ç›¸å¯¹äºGAN æ‰¹é‡å½’ä¸€åŒ–ï¼Œå»æ‰å…¨è¿æ¥å±‚...
- cGAN é€šè¿‡å¼•å…¥æ¡ä»¶ä¿¡æ¯æ¥æ§åˆ¶ç”Ÿæˆçš„æ•°æ®ï¼Œä»è€Œä½¿å¾—ç”Ÿæˆå™¨èƒ½å¤Ÿæ ¹æ®ç‰¹å®šçš„æ¡ä»¶ç”ŸæˆæŒ‡å®šç±»å‹çš„æ•°æ®ã€‚ç›¸è¾ƒäºä¼ ç»Ÿçš„ GANï¼ŒcGAN åœ¨ç”Ÿæˆæ•°æ®æ—¶ä¸å†å®Œå…¨ä¾èµ–äºéšæœºå™ªå£°å‘é‡ï¼Œè€Œæ˜¯å°†æŸäº›é¢å¤–çš„ä¿¡æ¯ï¼ˆå¦‚æ ‡ç­¾ã€å›¾åƒã€æ–‡æœ¬ç­‰ï¼‰ä½œä¸ºæ¡ä»¶è¾“å…¥åˆ°ç”Ÿæˆå™¨å’Œåˆ¤åˆ«å™¨ä¸­ã€‚è¿™ç§æ–¹æ³•æå‡äº†ç”Ÿæˆä»»åŠ¡çš„æ§åˆ¶æ€§å’Œçµæ´»æ€§ï¼Œå°¤å…¶æ˜¯åœ¨éœ€è¦ç”Ÿæˆç‰¹å®šç±»å‹æˆ–å…·æœ‰ç‰¹å®šå±æ€§çš„æ•°æ®æ—¶ã€‚(ä¸å®Œå…¨æ˜¯éšæœºå™ªå£°è¾“å…¥ï¼Œè€Œæ˜¯æœ‰æ„ä¹‰çš„ä¿¡æ¯)

GANä¹Ÿæœ‰ä¸€äº›limitations

1. finite sample size(training set is finite, not the full distribution)
2. limited capacity(the generator has limit capacity)
3. optimizer may stuck at local optima
4. hard to balance D and G ability
5. hard to find a maximum or minimum



## Adversarial Examples

1. How to fool?

   - perturbation: åœ¨åŸæœ‰åŸºç¡€ä¸Šåšå‡ºä¸€äº›è½»å¾®æ‰°åŠ¨ï¼Œè®©åˆ†ç±»å™¨misclassified

   - Gradient Ascent: easier to take small gradient steps in desired direction 

   - Linear Analysis: To fool a linear classifier, add a small multiple of the target class weights to the test example

     That is $f(x,\hat{y})=w^T x:xâ†x+Î· w$

   - Generating Adversarial example

     1. Fast gradient sign method(FGSM)

        <img src="image-20250105163429304.png" alt="image-20250105163429304" style="zoom:25%;" />

     2. Iterative gradient sign method(æ¯æ¬¡æ­¥é•¿æ¯”è¾ƒå°)

     3. Least likely class method

   - Black-box attack: é€šè¿‡ä½¿ç”¨åˆæˆè¾“å…¥æ•°æ®æ¥å­¦ä¹ ç›®æ ‡ç½‘ç»œçš„æ›¿ä»£æ¨¡å‹ï¼ˆsubstitute networkï¼‰ï¼Œç„¶åä½¿ç”¨è¯¥æ›¿ä»£æ¨¡å‹æ¥ç”Ÿæˆå¯¹æŠ—æ€§æ ·æœ¬ï¼ˆadversarial examplesï¼‰

2. Properties of Adversarial Examples

   1. å¯¹ä»»ä½•imageè¾“å…¥ï¼Œåº”è¯¥æ˜¯å¾ˆå®¹æ˜“ç”Ÿæˆå¾ˆç›¸ä¼¼çš„å›¾ç‰‡è®©ä»–misclassified
   2. å¹¶ä¸éœ€è¦precise gradient ascent
   3. Adversarial examplesæœ‰äº›æ—¶å€™æ˜¯åœ¨printed or photographedä¹‹åå¯ä»¥survive
   4. å¯èƒ½é€šè¿‡åŒæ ·çš„perturbationæ”»å‡»å¾ˆå¤šä¸åŒçš„Image
   5. è¿™æ ·çš„Adversarial exampleså¦‚æœèƒ½å¤Ÿfoolä¸€ä¸ªnetworkï¼Œé‚£ä¹ˆæœ‰å¾ˆå¤§æ¦‚ç‡ä¹Ÿèƒ½foolä¸åŒparameterçš„å…¶ä»–network

3. Why deep network easy to fool?

   1. è¿‡äºçº¿æ€§,å¾ˆå®¹æ˜“æ“ä½œoutput in a predictable way
   2. ç»´åº¦è¿‡é«˜ï¼Œåœ¨æŸä¸€ä¸ªç»´åº¦ä¸Šä¿®æ”¹å¾ˆå°çš„amountéš¾ä»¥å¯Ÿè§‰
   3. ç¥ç»ç½‘ç»œå¯ä»¥æ‹Ÿåˆä»»ä½•æ•°æ®ï¼Œä½†æ²¡æœ‰ä»»ä½•æœºåˆ¶é˜²æ­¢å®ƒä»¬åœ¨è®­ç»ƒæ ·æœ¬ä¹‹é—´è¡¨ç°ä¸ç¨³å®šã€‚åç›´è§‰åœ°ï¼Œä¸€ä¸ªç½‘ç»œå¯ä»¥åœ¨è‡ªç„¶å›¾åƒä¸Šå…·æœ‰è‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›ï¼Œä½†ä»ç„¶å®¹æ˜“å—åˆ°å¯¹æŠ—æ€§æ ·æœ¬çš„æ”»å‡»ã€‚

4. SO how to defend(main approaches)

   1. å¼ºåŒ–è®­ç»ƒï¼Œç”¨å¯¹æŠ—æ€§ä¾‹å­è¿›è¡Œå¼ºåŒ–è®­ç»ƒ (Train a separate model to reject adversarial examples: SafetyNet)
   2. Design highly **nonlinear** architectures robust to adversarial perturbations
   3. Pre-process input images to disrupt adversarial perturbations (æå‰è¿›è¡Œé™å™ªç­‰æ“ä½œå‡è½»å¯¹æŠ—æ€§æ‰°åŠ¨çš„æ•ˆæœ)



## Beyond vectors: DL on graphs

ä»‹ç»äº† Feature å’Œ Structure; å‰è€…æ˜¯ Object as set of extracted **features**ï¼Œè€Œåè€…å¼ºè°ƒObject as components in **relation** with each other

ä¸¤ä¸ªæ„å»ºGraphçš„é‡è¦çŸ©é˜µï¼šDegree Matrix(åªæœ‰å¯¹è§’çº¿ä¸Šæœ‰å…ƒç´ , D) && Adjacent Matrix(A)  è€ŒLaplacian Matrix L = D - A

ç›®å‰æ‰€å­¦çš„æ˜¯Learning based on vectors, HOWEVER, turning a graph into a vectorå¹¶ä¸easy, æ¯”å¦‚å›¾çš„sizeå¯èƒ½ä¼švaryä»¥åŠèŠ‚ç‚¹çš„orderä¼švary

**å‡ ç§Graph Learningçš„ç±»åˆ«(Graph Classification, Node Classification, Link Prediction)**

GCN **input: node features Matrix H (N nodes * F features) + Adjacent Matrix (N * N)**

GCN **output: Matrix Z(every row i is the output feature of node i)  OR single label of G**

$$
H(l+1) = RELU(AH(l)W(l))
$$
å¯¹äºä¸€å±‚çš„Layerè®¡ç®—å…¬å¼å¦‚ä¸Šï¼Œæ¯”æ–¹è¯´åœ¨l=0æ—¶å€™ï¼Œ$AH(l)$å°±æ˜¯é‚»æ¥çŸ©é˜µ(N\*N)å’Œnode-featureçŸ©é˜µçš„ä¹˜ç§¯(N\*F),æ¯ä¸€ç»„è¡Œä¹˜åˆ—éƒ½æ˜¯å¯¹äºæ¯ä¸ªèŠ‚ç‚¹çš„æŸä¸ªç‰¹å¾è€ƒè™‘äº†æ‰€æœ‰ç›¸é‚»èŠ‚ç‚¹çš„å¯¹åº”ç‰¹å¾å’Œ

HOWEVER æœ‰äº›é—®é¢˜ï¼š

1. The feature at node i is NOT included in the computation of the new aggregated feature at node i. ï¼ˆå› ä¸ºåœ¨è®¡ç®—æ—¶å€™è‡ªå·±çš„å¯¹åº”çš„é‚»æ¥çŸ©é˜µå€¼æ°¸è¿œæ˜¯0ï¼‰
2. æ¯ä¸ªnodeæœ‰ä¸åŒçš„degreeï¼Œå¯èƒ½ä¼šå¯¼è‡´gradient explosion or vanishing problem

THEN how to modify: 

1. æ·»åŠ ä¸€ä¸ªloopï¼Œä½¿å¾—æ—§çš„featureåœ¨æ–°çš„featureä¸­ä¿ç•™
2. Normalize A ä½¿å¾—scale of feature vectorä¸å˜



Node Classification: We can add a Softmax layer at the end and apply the GCN to predict the labels of the nodes of a graph, where some of the nodes already have labels (training set)

Graph Classification: The previous architecture can be extended to deal with graph classifications (i.e., one label per graph) by combining the node-level features in a single graph-level feature.



## Appendix

1. About Pytorch

   ````python
   # numpy ä¸ tensor ä¹‹é—´çš„ç›¸äº’è½¬æ¢
   data = [[1, 2],[3, 4]]
   # tensor to array
   x_tensor = torch.tensor(data); print(x_tensor)
   x_tensor2array = x_tensor.numpy(); print(x_tensor2array); print()
   # array to tensor
   x_array = np.array(data); print(x_array)
   x_array2tenor = torch.from_numpy(x_array); print(x_array2tenor)
   
   # empty/rand/ones/zeros/eye(), xxx_like()
   # the difference is you can fill dimensions without brackets at the beginning for these functions
   x = torch.empty(2, 3); print(x)
   x = torch.randn(2, 3); print(x) # initialization from the Gaussian distribution of N(0,1) randå°±æ˜¯ä¸€ä¸ªæ ¹æ®æ¦‚ç‡åˆ†å¸ƒçš„éšæœº
   # cuda() means translating your tensors into GPUs
   x = torch.zeros(2, 3, dtype=torch.float).cuda(); print(x) # if your device is CPU, please delete the cuda()
   y = torch.rand_like(x) # _like means the same shape, data type and device(GPU or CPU)
   print(y) 
   
   # np.squeeze() reduce the dimensions of "1"
   t = np.eye(5) # identity matrix
   print(t, t.shape)
   # åˆ›å»º5*5çš„one-hot representation
   ````

   ä¹˜æ³•æ—¶å€™éœ€è¦æ³¨æ„å‡ ç‚¹

   ````
   torch.mul() equals "*": Element-wise multiplication
   torch.mm(): the common mathematical matrix multiplication
   torch.matmul() equals "@": Matrix product of two tensors, it includes matrix multiplication methods of different dimensions
   ````

   

